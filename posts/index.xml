<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on My Blog</title>
    <link>https://cshung.github.io/posts/</link>
    <description>Recent content in Posts on My Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 17 Dec 2022 10:32:43 -0800</lastBuildDate><atom:link href="https://cshung.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Watch Soccer with SOCKS</title>
      <link>https://cshung.github.io/posts/soccer-with-socks/</link>
      <pubDate>Sat, 17 Dec 2022 10:32:43 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/soccer-with-socks/</guid>
      <description>As of the time of writing, tomorrow is the final for World Cup 2022. It is a pity to miss it. Unfortunately, in the US, unlike most other places in the world, you can&amp;rsquo;t watch it for free, while it is available for free online in many other countries.
To get around that restriction, I &amp;hellip;
 hosted a cheap Linux virtual machine on Azure. used SSH as a sock server.</description>
    </item>
    
    <item>
      <title>Debug MAUI Android</title>
      <link>https://cshung.github.io/posts/debug-maui-android/</link>
      <pubDate>Mon, 04 Apr 2022 08:20:54 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/debug-maui-android/</guid>
      <description>These days I have been helping the MAUI team to fix some bugs. I always learn something new when I work on something new, and this time is no different. Today I am going to write about how to debug the Android code running inside a MAUI app.
Procedure Step 1: Launching the App. I start the MAUI app in Visual Studio as usual. In this post, I am going to assume that we know how to start an App in Visual Studio.</description>
    </item>
    
    <item>
      <title>SA-IS Algorithm</title>
      <link>https://cshung.github.io/posts/sais/</link>
      <pubDate>Sun, 26 Dec 2021 10:52:35 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/sais/</guid>
      <description>Today, I would like to write about my understanding of the SA-IS algorithm for constructing a suffix array.
What is a suffix array? Consider the string &amp;ldquo;banana&amp;rdquo;, this string has 6 suffixes.
   suffix index     banana 0   anana 1   nana 2   ana 3   na 4   a 5    And if we sort them, we have these:</description>
    </item>
    
    <item>
      <title>Spurious Interrupts</title>
      <link>https://cshung.github.io/posts/spurious-interrupts/</link>
      <pubDate>Sat, 23 Oct 2021 16:32:21 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/spurious-interrupts/</guid>
      <description>Spurious interrupt In this post, we are going to talk about the spurious interrupt that we see in the console when running Xv6 on v86. I think it is a reflection of a deep problem in Xv6. To get started, let first explain what is a spurious interrupt.
The hardware side The best way to think of spurious interrupts is to think like the programmable interrupt controller (PIC) between the devices (e.</description>
    </item>
    
    <item>
      <title>PS/2 and A20</title>
      <link>https://cshung.github.io/posts/ps2-and-a20/</link>
      <pubDate>Fri, 22 Oct 2021 20:15:34 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/ps2-and-a20/</guid>
      <description>PS/2 and A20 If the title of the post doesn&amp;rsquo;t make any sense for you, you are just too young. Well, just kidding. These are really old technologies but still impacting our journey to host Xv6 on v86. In our last post, we were able to run a scenario, but it isn&amp;rsquo;t perfect, it looks like all keyboard inputs are ignored and one must input the command through the UART port.</description>
    </item>
    
    <item>
      <title>Ready to Run Delay Load</title>
      <link>https://cshung.github.io/posts/ready-to-run-delay-load/</link>
      <pubDate>Thu, 14 Oct 2021 12:27:20 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/ready-to-run-delay-load/</guid>
      <description>In this series of posts, I will deep dive into ReadyToRun to understand its mechanisms. In my previous post, I briefly explained what is ReadyToRun and what problems do we need to solve. Now we will look into the exact mechanisms.
The example We will start with this very simple example:
using System;  namespace ReadyToDebug {  class Program  {  static void Main(string[] args)  {  for (int i = 0; i &amp;lt; 3; i++)  {  Console.</description>
    </item>
    
    <item>
      <title>Optimize Bricks</title>
      <link>https://cshung.github.io/posts/optimize-bricks/</link>
      <pubDate>Wed, 06 Oct 2021 16:04:13 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/optimize-bricks/</guid>
      <description>In this post, I am going to talk about an optimization I made in the GC to reduce tail latency.
Scenario One of our customers reported that occassionally, they are observing gen 1 GC taking longer time than usual. Usually, their gen 1 GC takes around 4 milliseconds, but once in a while it could be as long as 15 milliseconds, and this is getting into their tail latencies measurements.</description>
    </item>
    
    <item>
      <title>Fake Interior Pointer</title>
      <link>https://cshung.github.io/posts/fake-interior-pointer/</link>
      <pubDate>Fri, 10 Sep 2021 09:50:21 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/fake-interior-pointer/</guid>
      <description>GC reporting basics When CoreCLR performs a garbage collection, the GC asks the VM where the roots are. The runtime will report to the GC the pointers to the pointers of the objects. This process is called GC reporting.
Suppose we have a pointer on the stack pointing to an object on the GC heap, it will look like this:
Stack: Heap 0x00001000: .......... 0x00F00000: ..........: .......... ..........: .......... ..........: .</description>
    </item>
    
    <item>
      <title>False Memory Leak</title>
      <link>https://cshung.github.io/posts/false-memory-leak/</link>
      <pubDate>Fri, 13 Aug 2021 12:18:40 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/false-memory-leak/</guid>
      <description>I am writing this post to share a memory leak investigation which turns out to be a false positive (i.e. we are not having a managed memory leak). This goal of this document is to share the analysis method so that it could be applied to similar situations.
Highlights Before I go into the details, here is a one line summary of the conclusion. This case is NOT a managed memory leak, but because a compiler generated temp is considered a reference and therefore the garbage collector cannot eliminate it.</description>
    </item>
    
    <item>
      <title>Memory Corruption (2)</title>
      <link>https://cshung.github.io/posts/memory-corruption-2/</link>
      <pubDate>Fri, 02 Jul 2021 15:01:10 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/memory-corruption-2/</guid>
      <description>Another memory corruption bug In this post, we will talk about another memory corruption bug I found and fix. Check out my previous post for more context and examples.
The symptom We are hitting an access violation at this location:
inline size_t my_get_size (Object* ob) {  MethodTable* mT = header(ob)-&amp;gt;GetMethodTable();   return (mT-&amp;gt;GetBaseSize() +  (mT-&amp;gt;HasComponentSize() ?  ((size_t)((CObjectHeader*)ob)-&amp;gt;GetNumComponents() * mT-&amp;gt;RawGetComponentSize()) : 0)); } When the access violation happens, mT is a nullptr and therefore it cannot be dereferenced.</description>
    </item>
    
    <item>
      <title>Memory Corruption (1)</title>
      <link>https://cshung.github.io/posts/memory-corruption-1/</link>
      <pubDate>Sat, 29 May 2021 11:09:44 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/memory-corruption-1/</guid>
      <description>Debugging a memory corruption problem A memory corruption issue refers to a problem that is caused by the fact that the memory content is wrong. For example, the code is having an access violation because it tried to dereference a pointer that is not valid. Debugging a memory corruption issue is hard because we don&amp;rsquo;t know how the process get into a corrupted state to begin with. In this post, I am going to share my experience debugging a memory issue caused by the GC.</description>
    </item>
    
    <item>
      <title>Git Merge Squash</title>
      <link>https://cshung.github.io/posts/git-merge-squash/</link>
      <pubDate>Wed, 21 Apr 2021 12:57:39 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/git-merge-squash/</guid>
      <description>Git Merge Squash This is a short article documenting my process of reusing someone else&amp;rsquo;s change. It is not particularly easy and therefore I would like a document to remember how I did it.
The problem? Imagine my partner and I were working on the same repository. I am working on a feature and he is working on a fix that I need. However, for whatever reasons, my partner couldn&amp;rsquo;t merge the fix in, but I would really like to apply his change in my code base so that my scenario work (at least locally), how should I do it?</description>
    </item>
    
    <item>
      <title>Understanding the brick table</title>
      <link>https://cshung.github.io/posts/brick/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/brick/</guid>
      <description>Understanding the brick table A brick table is a data structure that helps finding an object in the heap. To begin with the discussion, it makes sense to clarify what does finding an object mean.
What is the find object problem? There are various situation that we are given a random pointer inside the heap, and we wanted to find the pointer to the object that is using the address.</description>
    </item>
    
    <item>
      <title>Understanding the card table</title>
      <link>https://cshung.github.io/posts/card/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/card/</guid>
      <description>Understanding the card table A card table is used in a generational GC to discover cross-generational pointers. Let&amp;rsquo;s get started with the generation GC problem first.
Generational GC It is observed allocations typically divides into two classes. Either they are short-lived or they are long lived. To efficiently use the memory, we would like to be able to reclaim the space of the short lived object relatively fast without having to worry about the long lived ones.</description>
    </item>
    
    <item>
      <title>POH Tuning (Part 5 - Preliminary results)</title>
      <link>https://cshung.github.io/posts/poh-tuning-5/</link>
      <pubDate>Mon, 08 Mar 2021 10:57:05 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/poh-tuning-5/</guid>
      <description>Top level result After running, we can use the Jupyter notebook to analyze the result. The result is surprising. To make the data easy to analyze, they are available as pandas data frame. For those who are unfamiliar with pandas, a data frame is really just a table.
To use the notebook to get to the data frame, we need to run the first cell (as it required to setup the functions), and then we can run the cell calling the get_test_metrics_numbers_for_jupyter function, there should be exactly one such cell.</description>
    </item>
    
    <item>
      <title>POH Tuning (Part 6 - Varying the benchmark)</title>
      <link>https://cshung.github.io/posts/poh-tuning-6/</link>
      <pubDate>Mon, 08 Mar 2021 10:57:05 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/poh-tuning-6/</guid>
      <description>Varying the benchmark In the last post, we showed that in a particular scenario, allocating pinned objects on pinned object heap is a better choice from both the speed perspective and the heap size perspective. How about other scenarios?
In part 4, we already discussed the criterion what is feasible to test under GCPerfSim, so we will simply generate all the possibilities here with this simple Python script
for a in range(1, 100):  if 1000 % a == 0:  for b in range(1, a):  if a % b == 0:  if ((1000 - b) % (a - b) == 0):  pin_sohsi = 1000 // a  pin_sohpi = a // b  poh_sohsi = (1000 - b) // (a - b)  poh_pohar = b  print(&amp;#34; 2gb_pin_%s_%s:&amp;#34; % (a, b));  print(&amp;#34; arguments:&amp;#34;);  print(&amp;#34; tc: 6&amp;#34;);  print(&amp;#34; tagb: 100&amp;#34;);  print(&amp;#34; tlgb: 2&amp;#34;);  print(&amp;#34; lohar: 0&amp;#34;);  print(&amp;#34; pohar: 0&amp;#34;);  print(&amp;#34; sohsr: 100-4000&amp;#34;);  print(&amp;#34; pohsr: 100-4000&amp;#34;);  print(&amp;#34; sohsi: %s&amp;#34; % pin_sohsi);  print(&amp;#34; lohsi: 0&amp;#34;);  print(&amp;#34; pohsi: 0&amp;#34;);  print(&amp;#34; sohpi: %s&amp;#34; % pin_sohpi);  print(&amp;#34; lohpi: 0&amp;#34;);  print(&amp;#34; sohfi: 0&amp;#34;);  print(&amp;#34; lohfi: 0&amp;#34;);  print(&amp;#34; pohfi: 0&amp;#34;);  print(&amp;#34; allocType: reference&amp;#34;);  print(&amp;#34; testKind: time&amp;#34;);  print(&amp;#34; 2gb_poh_%s_%s:&amp;#34; % (a, b));  print(&amp;#34; arguments:&amp;#34;);  print(&amp;#34; tc: 6&amp;#34;);  print(&amp;#34; tagb: 100&amp;#34;);  print(&amp;#34; tlgb: 2&amp;#34;);  print(&amp;#34; lohar: 0&amp;#34;);  print(&amp;#34; pohar: %s&amp;#34; % poh_pohar);  print(&amp;#34; sohsr: 100-4000&amp;#34;);  print(&amp;#34; pohsr: 100-4000&amp;#34;);  print(&amp;#34; sohsi: %s&amp;#34; % poh_sohsi);  print(&amp;#34; lohsi: 0&amp;#34;);  print(&amp;#34; pohsi: 1&amp;#34;);  print(&amp;#34; sohpi: 0&amp;#34;);  print(&amp;#34; lohpi: 0&amp;#34;);  print(&amp;#34; sohfi: 0&amp;#34;);  print(&amp;#34; lohfi: 0&amp;#34;);  print(&amp;#34; pohfi: 0&amp;#34;);  print(&amp;#34; allocType: reference&amp;#34;);  print(&amp;#34; testKind: time&amp;#34;); Preprocessing the result As usual, we can create a pandas data frame for all the runs.</description>
    </item>
    
    <item>
      <title>POH Tuning (Part 4 - Benchmark design and the performance infrastructure)</title>
      <link>https://cshung.github.io/posts/poh-tuning-4/</link>
      <pubDate>Fri, 05 Mar 2021 19:55:26 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/poh-tuning-4/</guid>
      <description>Benchmark design Armed with the knowledge about how the allocation ratios works in the previous post. Now we can design our benchmarks. My goal is to produce a pair of benchmarks so that I can compare pinning objects by using the old pinned handle, or by the new pinned object heap.
In the pinned handle case, we can have a general design like this:
Out of 1,000 objects in the SOH, \( a \) of them survives and \( b \) of them are pinned.</description>
    </item>
    
    <item>
      <title>POH Tuning (Part 3 - Other statistical properties)</title>
      <link>https://cshung.github.io/posts/poh-tuning-3/</link>
      <pubDate>Mon, 01 Mar 2021 20:55:26 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/poh-tuning-3/</guid>
      <description>In the last post, we discussed what the benchmark does and how the weights are computed. In this post, we will talk about some other interesting statistical properties. The lesson learned here is that we know how objects behave in the benchmark, and we can use this to judge whether or not the benchmark actually matches with real-life use cases.
Object lifetime In this previous post, we know about an object&amp;rsquo;s life cycle.</description>
    </item>
    
    <item>
      <title>POH Tuning (Part 2 - What am I running?)</title>
      <link>https://cshung.github.io/posts/poh-tuning-2/</link>
      <pubDate>Mon, 01 Mar 2021 19:55:26 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/poh-tuning-2/</guid>
      <description>In the last post, we talk about the event tracing infrastructure, it allows us to measure the metrics we wanted to study when we run the program. But what program do we want to run? The program that we will run is called a benchmark. In this post, I will look into the details of the benchmark program.
Overview The program that we will run is called GCPerfSim. As its name suggests, it simulates workload for the GC to understand its performance.</description>
    </item>
    
    <item>
      <title>Debug Info Debugging</title>
      <link>https://cshung.github.io/posts/debug-info-debugging/</link>
      <pubDate>Mon, 18 Jan 2021 13:25:05 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/debug-info-debugging/</guid>
      <description>Recently, I have found an anomaly in the debug info generated by the ready to run compiler. In this post, I will talk about how I found it and how I debugged it.
Discovery In a routine update of the ILCompiler.Reflection.ReadyToRun.dll for ILSpy, I turned on the STRESS mode I introduced in a recent commit to test whether or not the new version can disassemble all the methods in System.Private.CoreLib. To my surprise, it failed with this exception.</description>
    </item>
    
    <item>
      <title>POH Tuning (Part 1 - What is my pinned object heap size?)</title>
      <link>https://cshung.github.io/posts/poh-tuning-1/</link>
      <pubDate>Fri, 15 Jan 2021 11:18:17 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/poh-tuning-1/</guid>
      <description>In this series, I am going to talk about my work to tune the pinned object heap. The first step to tuning is to understand how it performs now. Unfortunately, the tools for analyzing the performance is incomplete.
Pinned Object Heap size (and the event tracing mechanisms) With the tools available in .NET 5 time frame, we did not know the size of the pinned object heap. We had the information in the trace, but we did not have the parser to understand them.</description>
    </item>
    
    <item>
      <title>Generation Aware Analysis</title>
      <link>https://cshung.github.io/posts/generation-aware-analysis/</link>
      <pubDate>Tue, 05 Jan 2021 14:47:10 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/generation-aware-analysis/</guid>
      <description>The problem? The .NET GC is generational, it makes the assumption that allocations are broadly divided into two classes, either they are short-lived (e.g. temporary objects) or they are long-lived (e.g. constants, caches for repeated uses). This assumption is often true, but once in a while, that&amp;rsquo;s not true, often due to programmer mistakes. If a pile of objects meant for short-term usage is leaked into gen2, that can cost a short-term spike in ephemeral GC latency, and a long-term memory cost for storing them.</description>
    </item>
    
    <item>
      <title>How CoreCLR GC understand objects (part 2)</title>
      <link>https://cshung.github.io/posts/gc-objects-2/</link>
      <pubDate>Mon, 04 Jan 2021 14:14:15 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/gc-objects-2/</guid>
      <description>In addition to size described in an earlier post, it is also important for the GC to know where the pointers are in an object. This is because in the mark phase, we need to traverse the object graph. Here is a function for the mark phase in gc.cpp line 19415-19452.
Where is the code that perform the traversal? //this method assumes that *po is in the [low. high[ range void gc_heap::mark_object_simple (uint8_t** po THREAD_NUMBER_DCL) {  uint8_t* o = *po;  /* some code that does not change o or po */  if (gc_mark1 (o))  {  /* some code that does not change o or po */  {  go_through_object_cl (method_table(o), o, s, poo,  {  uint8_t* oo = *poo;  /* some code to recursively mark oo */  }  );  }  } } Imagine this is run during the mark phase, if we discover an unmarked object, then we traverse into its pointers and recursively mark the objects it points to.</description>
    </item>
    
    <item>
      <title>How CoreCLR GC understand objects (part 1)</title>
      <link>https://cshung.github.io/posts/gc-objects-1/</link>
      <pubDate>Mon, 04 Jan 2021 12:11:37 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/gc-objects-1/</guid>
      <description>In this series of posts, I am going to explain how the GC understand objects. In this part, we will focus on size.
Why does it matter? The GC expects the heap to be tightly packed with objects. It scans the heap by starting at the beginning of the heap and walk the object one-by-one by this simple algorithm. This is real code excerpt from gc.cpp line 22972 to 23002, out of dotnet/runtime repo, tag v5.</description>
    </item>
    
    <item>
      <title>Hello Reflection</title>
      <link>https://cshung.github.io/posts/hello-reflection/</link>
      <pubDate>Sat, 05 Dec 2020 14:53:55 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/hello-reflection/</guid>
      <description>To get started using ILCompiler.Reflection.ReadyToRun, let&amp;rsquo;s construct a simple HelloWorld project. If you don&amp;rsquo;t know what it is, please take a look at the previous post.
Getting started We will create a .NET Core console application. Create a folder named HelloReflection and invoke dotnet new console.
C:\dev&amp;gt;mkdir HelloReflection C:\dev&amp;gt;cd HelloReflection C:\dev\HelloReflection&amp;gt;dotnet new console The template &amp;#34;Console Application&amp;#34; was created successfully. Processing post-creation actions... Running &amp;#39;dotnet restore&amp;#39; on C:\dev\HelloReflection\HelloReflection.csproj... Determining projects to restore.</description>
    </item>
    
    <item>
      <title>Debugging help for CoreCLR GC - Mono</title>
      <link>https://cshung.github.io/posts/coreclrgc-mono/</link>
      <pubDate>Fri, 04 Dec 2020 11:52:15 -0800</pubDate>
      
      <guid>https://cshung.github.io/posts/coreclrgc-mono/</guid>
      <description>I was invited to help with debugging an issue in the CoreCLR GC - Mono project. In this blog entry, I am planning to describe the debugging process so that it can be repeated to move the project forward.
What is CoreCLR GC - Mono? CoreCLR GC - Mono is an attempt to use CoreCLR&amp;rsquo;s GC to replace sgen, a simple generational garbage collector for Mono. The major goal of the project is to improve performance.</description>
    </item>
    
    <item>
      <title>Automate WinDBG</title>
      <link>https://cshung.github.io/posts/automate-windbg/</link>
      <pubDate>Mon, 31 Aug 2020 17:01:33 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/automate-windbg/</guid>
      <description>Automate WinDBG WinDBG is a very convenient debugger, but typing the same command again and again is tiresome, especially during startup. GDB provided a mechanism to run some commands on startup through gdbinit. WinDBG has the equivalent, although it is not as clear. In this blog post, I am going to share how I automated WinDBG to run some commands on startup. For the impatient, just rush to the summary to get the commands.</description>
    </item>
    
    <item>
      <title>ILSpy.ReadyToRun</title>
      <link>https://cshung.github.io/posts/ilspy-readytorun/</link>
      <pubDate>Sat, 25 Jul 2020 19:50:22 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/ilspy-readytorun/</guid>
      <description>Introduction ILSpy.ReadyToRun is my side project. It is a plugin in ILSpy that allow us to inspect the precompiled code in a ReadyToRun image. My vision is to make all information available in a ready to run image to be displayed in a human readable manner.
What can it do? If you open a ReadyToRun image in ILSpy, it will show up exactly as it was. You can see all the types, the methods, and the decompiled C# code, as usual.</description>
    </item>
    
    <item>
      <title>Xv6 on v86</title>
      <link>https://cshung.github.io/posts/xv6-on-v86/</link>
      <pubDate>Sun, 28 Jun 2020 09:27:30 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/xv6-on-v86/</guid>
      <description>Xv6 on v86 In this post, I will talk about my journey to get Xv6 running on v86. Xv6 is a unix-like teaching OS developed by MIT. v86 is an x86 virtual machine running on the browser developed by Fabian.
The key characteristic of these two systems is that they are simple compared to their industrial-strength counterparts (compared to the Linux kernel or the QEMU emulator). Being simple, it is easy to understand.</description>
    </item>
    
    <item>
      <title>Introduction to ILCompiler.Reflection.ReadyToRun</title>
      <link>https://cshung.github.io/posts/introduction-to-ilcompiler-reflection-readytorun/</link>
      <pubDate>Thu, 25 Jun 2020 08:08:17 -0700</pubDate>
      
      <guid>https://cshung.github.io/posts/introduction-to-ilcompiler-reflection-readytorun/</guid>
      <description>Introduction ILCompiler.Reflection.ReadyToRun.dll is a new library I introduced in late 2019. It is meant to make the data embedded in a ReadyToRun binary available for access.
Background What is ReadyToRun? ReadyToRun is a new native compilation technology for .NET Core. For people who know about NGEN, it can be roughly thought as the .NET Core version of NGEN.
What is native compilation? When a managed language (such as C#) is compiled, it is compiled into an intermediate language named MSIL.</description>
    </item>
    
  </channel>
</rss>
